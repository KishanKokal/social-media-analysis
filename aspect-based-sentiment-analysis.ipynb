{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/torch/_utils.py:836: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/opt/homebrew/lib/python3.11/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_lg' (3.6.0) was trained with spaCy v3.6.0 and may not be 100% compatible with the current version (3.7.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/homebrew/lib/python3.11/site-packages/tensorflow_hub/__init__.py:61: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  from pkg_resources import parse_version\n",
      "/opt/homebrew/lib/python3.11/site-packages/pkg_resources/__init__.py:2846: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n",
      "/opt/homebrew/lib/python3.11/site-packages/pkg_resources/__init__.py:2846: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n",
      "/opt/homebrew/lib/python3.11/site-packages/pkg_resources/__init__.py:2331: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(parent)\n",
      "/opt/homebrew/lib/python3.11/site-packages/pkg_resources/__init__.py:2846: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.logging')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n",
      "/opt/homebrew/lib/python3.11/site-packages/pkg_resources/__init__.py:2846: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n"
     ]
    }
   ],
   "source": [
    "from setfit import AbsaModel\n",
    "\n",
    "model = AbsaModel.from_pretrained(\n",
    "    \"tomaarsen/setfit-absa-paraphrase-mpnet-base-v2-restaurants-aspect\",\n",
    "    \"tomaarsen/setfit-absa-paraphrase-mpnet-base-v2-restaurants-polarity\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# Define your YouTube API key\n",
    "api_key = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Define the video ID of the YouTube video you want to fetch comments for\n",
    "video_id = \"dtp6b76pMak\"\n",
    "\n",
    "# Create a YouTube Data API client\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "# Fetch comments from the YouTube video using the YouTube Data API\n",
    "comments = []\n",
    "next_page_token = None\n",
    "count = 0\n",
    "\n",
    "while count < 1000:\n",
    "    response = youtube.commentThreads().list(\n",
    "        part=\"snippet\",\n",
    "        videoId=video_id,\n",
    "        maxResults=100,  # Adjust as needed\n",
    "        pageToken=next_page_token\n",
    "    ).execute()\n",
    "\n",
    "    for item in response['items']:\n",
    "        count += 1\n",
    "        comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "        comments.append(comment)\n",
    "\n",
    "    next_page_token = response.get('nextPageToken')\n",
    "\n",
    "    if not next_page_token:\n",
    "        break\n",
    "\n",
    "# Write comments to a CSV file\n",
    "with open(\"youtube_data.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow([\"comment_text\"])  # Write header\n",
    "    for comment in comments:\n",
    "        writer.writerow([comment])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1000/1000 [04:02<00:00,  4.12it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import swifter\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"youtube_data.csv\")\n",
    "\n",
    "# Define a function to perform aspect-based sentiment analysis and store results in a new column\n",
    "def perform_absa(review):\n",
    "    absa_result = model.predict([review])[0]  # Get the first result\n",
    "    return absa_result\n",
    "\n",
    "# Apply the function to each row in the DataFrame using parallel processing\n",
    "df['aspect_sentiment'] = df['comment_text'].swifter.apply(perform_absa)\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "df.to_csv(\"output_file.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1          [{'span': 'display', 'polarity': 'negative'}]\n",
      "2      [{'span': 'helmet', 'polarity': 'positive'}, {...\n",
      "7      [{'span': 'TVs', 'polarity': 'neutral'}, {'spa...\n",
      "10     [{'span': 'killer apps', 'polarity': 'negative...\n",
      "16     [{'span': 'orange site', 'polarity': 'positive...\n",
      "                             ...                        \n",
      "988      [{'span': 'AR headset', 'polarity': 'neutral'}]\n",
      "990    [{'span': 'apps', 'polarity': 'neutral'}, {'sp...\n",
      "991    [{'span': 'Lawnmower man', 'polarity': 'neutra...\n",
      "995         [{'span': 'product', 'polarity': 'neutral'}]\n",
      "997         [{'span': 'iphones', 'polarity': 'neutral'}]\n",
      "Name: aspect_sentiment, Length: 474, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('output_file.csv')\n",
    "\n",
    "# Drop rows where the aspect_sentiment column contains '[]'\n",
    "df = df[df['aspect_sentiment'] != '[]']\n",
    "df['aspect_sentiment'] = df['aspect_sentiment'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "# Display the resulting DataFrame\n",
    "print(df['aspect_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 25 aspects for each polarity are stored in 'top_aspects.json'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "# Extract aspects and polarities and count occurrences\n",
    "aspect_polarity_counts = Counter()\n",
    "\n",
    "for entries in df['aspect_sentiment']:\n",
    "    try: \n",
    "        for entry in entries:\n",
    "            span = entry['span']\n",
    "            polarity = entry['polarity']\n",
    "            aspect_polarity_counts[(span, polarity)] += 1\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "# Separate counts for negative, positive, and neutral aspects\n",
    "negative_aspects = {}\n",
    "positive_aspects = {}\n",
    "neutral_aspects = {}\n",
    "\n",
    "for aspect_polarity, count in aspect_polarity_counts.items():\n",
    "    aspect, polarity = aspect_polarity\n",
    "    if polarity == 'negative':\n",
    "        negative_aspects[aspect] = count\n",
    "    elif polarity == 'positive':\n",
    "        positive_aspects[aspect] = count\n",
    "    else:\n",
    "        neutral_aspects[aspect] = count\n",
    "\n",
    "# Get the top 25 negative, positive, and neutral aspects\n",
    "top_negative_aspects = sorted(negative_aspects.items(), key=lambda x: x[1], reverse=True)[:25]\n",
    "top_positive_aspects = sorted(positive_aspects.items(), key=lambda x: x[1], reverse=True)[:25]\n",
    "top_neutral_aspects = sorted(neutral_aspects.items(), key=lambda x: x[1], reverse=True)[:25]\n",
    "\n",
    "# Store the top aspects in a dictionary\n",
    "top_aspects = {\n",
    "    \"negative\": top_negative_aspects,\n",
    "    \"positive\": top_positive_aspects,\n",
    "    \"neutral\": top_neutral_aspects\n",
    "}\n",
    "\n",
    "# Write the dictionary to a JSON file\n",
    "with open('top_aspects.json', 'w') as f:\n",
    "    json.dump(top_aspects, f, indent=4)\n",
    "\n",
    "print(\"Top 25 aspects for each polarity are stored in 'top_aspects.json'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from setfit import AbsaModel\n",
    "\n",
    "# Load the JSON file containing aspects and suggestions\n",
    "with open('top_aspects.json', 'r') as f:\n",
    "    aspects_with_suggestions = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_lg' (3.6.0) was trained with spaCy v3.6.0 and may not be 100% compatible with the current version (3.7.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "from setfit import AbsaModel\n",
    "\n",
    "model = AbsaModel.from_pretrained(\n",
    "    \"tomaarsen/setfit-absa-paraphrase-mpnet-base-v2-restaurants-aspect\",\n",
    "    \"tomaarsen/setfit-absa-paraphrase-mpnet-base-v2-restaurants-polarity\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def provide_suggestions(user_review, aspects_with_suggestions, model):\n",
    "    # Extract aspects using ABSA model\n",
    "    aspects = model(user_review)\n",
    "\n",
    "    # Print extracted aspects\n",
    "    print(\"Extracted Aspects:\")\n",
    "    for aspect in aspects:\n",
    "        aspect_text = aspect['span']\n",
    "        polarity = aspect['polarity']\n",
    "        print(f\"Aspect: {aspect_text} (Polarity: {polarity})\")\n",
    "\n",
    "        # Match extracted aspects with suggestions in the JSON file and print suggestions\n",
    "        found = False\n",
    "        for entry in aspects_with_suggestions[polarity]:\n",
    "            if isinstance(entry[0], str) and entry[0].lower() == aspect_text.lower():\n",
    "                print(f\"Suggestion for {aspect_text} (Polarity: {polarity}): {entry[1]}\")\n",
    "                found = True\n",
    "                break\n",
    "\n",
    "        # If no suggestions found for the aspect\n",
    "        if not found:\n",
    "            if polarity == 'negative':\n",
    "                print(f\"{aspect_text} needs improvement.\")\n",
    "            elif polarity == 'positive':\n",
    "                print(f\"{aspect_text} is loved by a certain group of audience.\")\n",
    "            elif polarity == 'neutral':\n",
    "                print(f\"There is a scope of improvement for {aspect_text}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Aspects:\n",
      "Aspect: gadget (Polarity: neutral)\n",
      "Suggestion for gadget (Polarity: neutral): 4\n",
      "Aspect: hearing aid device (Polarity: neutral)\n",
      "There is a scope of improvement for hearing aid device.\n",
      "Aspect: product (Polarity: neutral)\n",
      "Suggestion for product (Polarity: neutral): 11\n",
      "Aspect: price (Polarity: negative)\n",
      "Suggestion for price (Polarity: negative): 10\n",
      "Aspect: battery life (Polarity: positive)\n",
      "Suggestion for battery life (Polarity: positive): 3\n",
      "Aspect: battery solution (Polarity: positive)\n",
      "battery solution is loved by a certain group of audience.\n",
      "Aspect: price (Polarity: positive)\n",
      "Suggestion for price (Polarity: positive): 9\n"
     ]
    }
   ],
   "source": [
    "user_review = input(\"Please enter your review: \")\n",
    "\n",
    "# Call the function to provide suggestions\n",
    "provide_suggestions(user_review, aspects_with_suggestions, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
